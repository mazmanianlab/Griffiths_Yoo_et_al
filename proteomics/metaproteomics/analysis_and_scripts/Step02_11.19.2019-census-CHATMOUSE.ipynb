{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import cm\n",
    "from collections import OrderedDict\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as colors\n",
    "import re\n",
    "\n",
    "import bokeh.io\n",
    "import bokeh.models\n",
    "import bokeh.palettes\n",
    "import bokeh.plotting\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "bokeh.io.output_notebook\n",
    "\n",
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002744913101196289\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "#------------------------------Using Raw Census PLine Output---------------------------------\n",
    "\n",
    "def extract_PLines(census_file):\n",
    "    \"\"\"\n",
    "        Input: Census filled file (extracting intensities from P-Line)\n",
    "        Output: New dataframe containing data from census PLine\n",
    "    \"\"\"\n",
    "    with open(census_file, 'r') as f:\n",
    "        file1 = f.readlines()\n",
    "    with open('dump1.txt', 'w') as g:    \n",
    "        for line1 in file1:\n",
    "            line2 = line1.split('\\t')\n",
    "            if line2[0] == 'PLINE':\n",
    "                g.write(line1)\n",
    "            elif line2[0] == 'P':\n",
    "                g.write(line1)\n",
    "    temp_df1 = pd.read_csv('dump1.txt', sep='\\t', na_values='-').fillna(0)\n",
    "    return temp_df1\n",
    "\n",
    "def extract_Norm_Raw_PLine_Intensities(temp_df_NR1):\n",
    "    \"\"\"\n",
    "        Input: dataframe derived from 'extract_PLines' \n",
    "        Output: new dataframe containing normalized intensities for each protein/sample\n",
    "    \"\"\"\n",
    "    #Import Select Columns to new dataframe then add 1 to every intensity value (to ensure no 0 values)\n",
    "    temp_df_NR2 = temp_df_NR1[['ACCESSION', 'DESCRIPTION', 'NORM_INTENSITY_1', 'NORM_INTENSITY_2', 'NORM_INTENSITY_3', 'NORM_INTENSITY_4', 'NORM_INTENSITY_5', 'NORM_INTENSITY_6', 'NORM_INTENSITY_7', 'NORM_INTENSITY_8', 'NORM_INTENSITY_9', 'NORM_INTENSITY_10', 'NORM_INTENSITY_11', 'NORM_INTENSITY_12', 'NORM_INTENSITY_13', 'NORM_INTENSITY_14', 'NORM_INTENSITY_15', 'NORM_INTENSITY_16', 'NORM_INTENSITY_17']].copy()\n",
    "    temp_df_NR2[['NORM_INTENSITY_1', 'NORM_INTENSITY_2', 'NORM_INTENSITY_3', 'NORM_INTENSITY_4', 'NORM_INTENSITY_5', 'NORM_INTENSITY_6', 'NORM_INTENSITY_7', 'NORM_INTENSITY_8', 'NORM_INTENSITY_9', 'NORM_INTENSITY_10', 'NORM_INTENSITY_11', 'NORM_INTENSITY_12', 'NORM_INTENSITY_13', 'NORM_INTENSITY_14', 'NORM_INTENSITY_15', 'NORM_INTENSITY_16', 'NORM_INTENSITY_17']] += 1\n",
    "    return temp_df_NR2\n",
    "\n",
    "def extract_Raw_PLine_Intensities(temp_df_R1):\n",
    "    \"\"\"\n",
    "        Input: dataframe derived from 'extract_PLines'\n",
    "        Output: new dataframe containing non-normalized intensities for each protein/sample\n",
    "    \"\"\"\n",
    "    #Import Select Columns to new dataframe then add 1 to every intensity value (to ensure no 0 values)\n",
    "    temp_df_R2 = temp_df_R1[['ACCESSION', 'DESCRIPTION', 'INTENSITY_1', 'INTENSITY_2', 'INTENSITY_3', 'INTENSITY_4', 'INTENSITY_5', 'INTENSITY_6', 'INTENSITY_7', 'INTENSITY_8', 'INTENSITY_9', 'INTENSITY_10', 'INTENSITY_11', 'INTENSITY_12', 'INTENSITY_13', 'INTENSITY_14', 'INTENSITY_15', 'INTENSITY_16', 'INTENSITY_17']].copy()\n",
    "    temp_df_R2[['INTENSITY_1', 'INTENSITY_2', 'INTENSITY_3', 'INTENSITY_4', 'INTENSITY_5', 'INTENSITY_6', 'INTENSITY_7', 'INTENSITY_8', 'INTENSITY_9', 'INTENSITY_10', 'INTENSITY_11', 'INTENSITY_12', 'INTENSITY_13', 'INTENSITY_14', 'INTENSITY_15', 'INTENSITY_16', 'INTENSITY_17']] += 1\n",
    "    return temp_df_R2\n",
    "\n",
    "def normalize_Raw_PLine_Intensities(temp_df_R3):\n",
    "    \"\"\"\n",
    "        Input: non-normalized intensities dataframe from 'extract_Raw_PLine_Intensities' function\n",
    "        Output: return same dataframe with normalized intensity values; each value in a column is divided by its specific column sum\n",
    "    \"\"\"\n",
    "    temp_allsums1 = temp_df_R3.sum(axis=0, skipna = True)\n",
    "    temp_df_R3['INTENSITY_1'] /= temp_allsums1['INTENSITY_1']\n",
    "    temp_df_R3['INTENSITY_2'] /= temp_allsums1['INTENSITY_2']\n",
    "    temp_df_R3['INTENSITY_3'] /= temp_allsums1['INTENSITY_3']\n",
    "    temp_df_R3['INTENSITY_4'] /= temp_allsums1['INTENSITY_4']\n",
    "    temp_df_R3['INTENSITY_5'] /= temp_allsums1['INTENSITY_5']\n",
    "    temp_df_R3['INTENSITY_6'] /= temp_allsums1['INTENSITY_6']\n",
    "    temp_df_R3['INTENSITY_7'] /= temp_allsums1['INTENSITY_7']\n",
    "    temp_df_R3['INTENSITY_8'] /= temp_allsums1['INTENSITY_8']\n",
    "    temp_df_R3['INTENSITY_9'] /= temp_allsums1['INTENSITY_9']\n",
    "    temp_df_R3['INTENSITY_10'] /= temp_allsums1['INTENSITY_10']\n",
    "    temp_df_R3['INTENSITY_11'] /= temp_allsums1['INTENSITY_11']\n",
    "    temp_df_R3['INTENSITY_12'] /= temp_allsums1['INTENSITY_12']\n",
    "    temp_df_R3['INTENSITY_13'] /= temp_allsums1['INTENSITY_13']\n",
    "    temp_df_R3['INTENSITY_14'] /= temp_allsums1['INTENSITY_14']\n",
    "    temp_df_R3['INTENSITY_15'] /= temp_allsums1['INTENSITY_15']\n",
    "    temp_df_R3['INTENSITY_16'] /= temp_allsums1['INTENSITY_16']\n",
    "    temp_df_R3['INTENSITY_17'] /= temp_allsums1['INTENSITY_17']\n",
    "    return temp_df_R3\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "#----------------------------Clustering Proteins - Census SLine-----------------------------\n",
    "\n",
    "\n",
    "def extract_SLine_from_Census(census_file):\n",
    "    \"\"\"\n",
    "        Input: Census 'filled' file\n",
    "        Output: text dump and returns a peptide dataframe\n",
    "    \"\"\"\n",
    "    with open(census_file, 'r') as f:\n",
    "        file1 = f.readlines()\n",
    "    with open('dump1.txt', 'w') as g:\n",
    "        for line1 in file1:\n",
    "            if (line1[0] == 'SLINE') or (line1[0] == 'S'):\n",
    "                g.write(line1)\n",
    "    df1 = pd.read_csv('dump1.txt', sep='\\t', header=0).fillna('0')\n",
    "    return df1\n",
    "\n",
    "def select_Census_Columns_Peptides(temp_df1):\n",
    "    \"\"\"\n",
    "        Input: raw census peptide (SLine) dataframe [Reliant on 'extract_SLine_from_Census']\n",
    "        Output: new cleaned up dataframe containing peptides (no duplicates) and corresponding intensities for each run\n",
    "    \"\"\"\n",
    "    #Note that columns below represent Peptide sequence and Intensity Columns -- CHANGE AS NECESSARY\n",
    "    temp_df2 = temp_df1[['SEQUENCE','INTENSITY_1','INTENSITY_2','INTENSITY_3','INTENSITY_4','INTENSITY_5','INTENSITY_6','INTENSITY_7','INTENSITY_8','INTENSITY_9','INTENSITY_10','INTENSITY_11','INTENSITY_12','INTENSITY_13','INTENSITY_14','INTENSITY_15','INTENSITY_16','INTENSITY_17']].copy()\n",
    "    \n",
    "    #Remove rows containing duplicate information (i.e. intensities); Duplicate peptides with different intensities are kept\n",
    "    temp_df3 = temp_df2.drop_duplicates(keep='first', inplace=False)\n",
    "    \n",
    "    #Reformatting Peptides to remove C- and N-terminal cleavage sites and diff-mod sites\n",
    "    temp_col1 = temp_df3['SEQUENCE']\n",
    "    temp_col2 = []\n",
    "    for temp_position1,temp_item1 in enumerate(temp_col1):\n",
    "        temp_col2.append(temp_item1[2:-2].replace('(15.994915)', ''))\n",
    "    temp_df3 = temp_df3.reset_index()\n",
    "    del temp_df3['index']\n",
    "    temp_df4 = temp_df3.copy()\n",
    "    temp_df4['PEPTIDE'] = pd.Series(temp_col2, index=temp_df4.index)\n",
    "    \n",
    "    #Create new cleaned up dataframe\n",
    "    temp_df5 = temp_df4[['PEPTIDE', 'INTENSITY_1', 'INTENSITY_2', 'INTENSITY_3', 'INTENSITY_4', 'INTENSITY_5', 'INTENSITY_6', 'INTENSITY_7', 'INTENSITY_8', 'INTENSITY_9', 'INTENSITY_10', 'INTENSITY_11', 'INTENSITY_12', 'INTENSITY_13', 'INTENSITY_14', 'INTENSITY_15', 'INTENSITY_16', 'INTENSITY_17']]\n",
    "    temp_df6 = temp_df5.drop_duplicates(keep='first', inplace=False)\n",
    "    temp_df6 = temp_df6.reset_index()\n",
    "    del temp_df6['index']\n",
    "    \n",
    "    #Sort new cleaned up dataframe and sum intensities columns for identical peptides\n",
    "    temp_df6.sort_values('PEPTIDE')\n",
    "    temp_df7 = temp_df6.groupby(['PEPTIDE']).sum()\n",
    "    return temp_df7\n",
    "\n",
    "def extract_PLine_from_Census(census_file):\n",
    "    \"\"\"\n",
    "        Input: census \"filled\" file\n",
    "        Output: text dump and returns a dictionary connecting peptides (key) and protein list (value) redundant proteins included\n",
    "    \"\"\"\n",
    "    #open census file\n",
    "    with open(census_file, 'r') as f:\n",
    "        file1 = f.readlines()\n",
    "    #generate new file containing protein PLines\n",
    "    with open('dump2.txt', 'w') as g:\n",
    "        temp_pep_list1 = []\n",
    "        for line1 in file1:\n",
    "            line2 = line1.split('\\t')\n",
    "            if (line2[0] == 'P'):\n",
    "                temp_pep_list2 = list(set(temp_pep_list1))\n",
    "                for item1 in temp_pep_list2:\n",
    "                    g.write('\\t' + item1 + '\\n')\n",
    "                temp_pep_list1 = []\n",
    "                g.write(line2[1] + '\\t' + line2[2] + '\\n')\n",
    "            elif (line2[0] == 'S'):\n",
    "                temp_pep_list1.append(line2[2][2:-2].replace('(15.994915)', ''))\n",
    "        temp_pep_list2 = list(set(temp_pep_list1))\n",
    "        for item1 in temp_pep_list2:\n",
    "            g.write('\\t' + item1 + '\\n')\n",
    "            temp_pep_list1 = []\n",
    "    \n",
    "    #open newly created protein PLine file\n",
    "    with open('dump2.txt', 'r') as f:\n",
    "        file2 = f.readlines()\n",
    "    \n",
    "    #create peptide(key)-protein(value) dictionary; proteins are assembled in list\n",
    "    Pep_to_Prot_Dict1 = {}\n",
    "    temp_prot1 = \"\"\n",
    "    for line1 in file2:\n",
    "        line2 = line1.split('\\t')\n",
    "        if line2[0] != '':\n",
    "            temp_prot1 = line2[0]\n",
    "        else:\n",
    "            if line2[1].replace('\\n', '') in Pep_to_Prot_Dict1.keys():\n",
    "                Pep_to_Prot_Dict1[line2[1].replace('\\n', '')].append(temp_prot1)\n",
    "            else:\n",
    "                Pep_to_Prot_Dict1[line2[1].replace('\\n', '')] = []\n",
    "                Pep_to_Prot_Dict1[line2[1].replace('\\n', '')].append(temp_prot1)\n",
    "    return Pep_to_Prot_Dict1\n",
    "\n",
    "def map_Clusters_to_Peptides(cluster_file):\n",
    "    \"\"\"\n",
    "        Input: CDHIT cluster file\n",
    "        Output: dictionary connecting Protein (keys) to Cluster number (values)\n",
    "    \"\"\"\n",
    "    #create dictionary connecting protein (keys) and cluster number (values)\n",
    "    with open(cluster_file, 'r') as f:\n",
    "        file1 = f.readlines() \n",
    "    temp_cluster_num = \"\"\n",
    "    Protein_to_Cluster_Dict1 = {}\n",
    "    for line1 in file1:\n",
    "        line2 = line1.split('\\t')        \n",
    "        if '>' in line2[0]:\n",
    "            temp_cluster_num = line2[0].replace('>', '').replace('\\n', '').replace('Cluster ', '')\n",
    "        else:\n",
    "            line3 = line2[1].split(' ')\n",
    "            line4 = line3[1].split('|')\n",
    "            line5 = line4[1]\n",
    "            Protein_to_Cluster_Dict1[line5] = temp_cluster_num\n",
    "    return Protein_to_Cluster_Dict1\n",
    "\n",
    "def map_Clusternum_to_Peptides(prot_to_clust_dict2, pep_to_prot_dict2):\n",
    "    \"\"\"\n",
    "        Input: 2 dictionaries: protein-cluster and peptide-protein\n",
    "        Output: dictionary linking peptides(key) to cluster number (value)\n",
    "    \"\"\"\n",
    "    pep_to_cluster_dict1 = {}\n",
    "    for item1 in pep_to_prot_dict2.keys():\n",
    "        temp_protlist1 = pep_to_prot_dict2[item1]\n",
    "        temp_cluster_list1 = []\n",
    "        for item2 in temp_protlist1:\n",
    "            try:\n",
    "                temp_cluster_list1.append(prot_to_clust_dict2[item2])\n",
    "            except:\n",
    "                pass\n",
    "        pep_to_cluster_dict1[item1] = list(set(temp_cluster_list1))\n",
    "    return pep_to_cluster_dict1\n",
    "\n",
    "def clusternum_to_PepDataframe(pep_to_clust_dict, uniquepep_dataframe):\n",
    "    \"\"\"\n",
    "        Input: Peptide-to-Cluster dictionary generated from 'map_Clusternum_to_Peptides' function and cleaned-up Peptide-Intensity dataframe from 'select_Census_Columns_Peptides' function\n",
    "        Output: New peptide-intensity dataframe with integrated cluster number column; Note that peptides with no cluster belong to contaminant or reverse proteins\n",
    "    \"\"\"\n",
    "    temp_df1 = uniquepep_dataframe.reset_index()\n",
    "    temp_list1 = list(temp_df1['PEPTIDE'])\n",
    "    temp_clusterlist1 = []\n",
    "    for item1 in temp_list1:\n",
    "        temp_clusterlist1.append(pep_to_clust_dict[item1])\n",
    "    temp_df1['CLUSTER'] = pd.Series(temp_clusterlist1, index=temp_df1.index)\n",
    "    temp_df2 = temp_df1[['PEPTIDE', 'CLUSTER', 'INTENSITY_1', 'INTENSITY_2', 'INTENSITY_3', 'INTENSITY_4', 'INTENSITY_5', 'INTENSITY_6', 'INTENSITY_7', 'INTENSITY_8', 'INTENSITY_9', 'INTENSITY_10', 'INTENSITY_11', 'INTENSITY_12', 'INTENSITY_13', 'INTENSITY_14', 'INTENSITY_15', 'INTENSITY_16', 'INTENSITY_17']]\n",
    "    return temp_df2\n",
    "\n",
    "def extract_Intensity_Master(census_file1, cluster_file1):\n",
    "    \"\"\"\n",
    "        Input: census 'filled' file and CDHIT cluster file\n",
    "        Output: Dataframe with Peptide, Cluster, and Intensity Columns\n",
    "    \"\"\"\n",
    "    temp_df1A = extract_SLine_from_Census(census_file1)\n",
    "    temp_df2A = select_Census_Columns_Peptides(temp_df1A)\n",
    "    temp_dict1A = extract_PLine_from_Census(census_file1)\n",
    "    temp_dict2A = map_Clusters_to_Peptides(cluster_file1)\n",
    "    temp_dict3A = map_Clusternum_to_Peptides(temp_dict2A, temp_dict1A)\n",
    "    temp_df3A = clusternum_to_PepDataframe(temp_dict3A, temp_df2A)\n",
    "    return temp_df3A\n",
    "\n",
    "def create_Cluster_Intensity_Table(complete_dataframe):\n",
    "    \"\"\"\n",
    "        Input: complete master dataframe from 'extract_Intensity_Master'\n",
    "        Output: new dataframe with intensities summed by cluster\n",
    "    \"\"\"\n",
    "    #Collect only peptides that map to 1 cluster\n",
    "    temp_df1A = complete_dataframe.loc[complete_dataframe['CLUSTER'].str.len() == 1]\n",
    "    #Create new column (ClusterID) then sum intensities belonging to the same cluster\n",
    "    temp_list1 = temp_df1A['CLUSTER']\n",
    "    temp_list2 = []\n",
    "    for item1 in temp_list1:\n",
    "        temp_list2.append(item1[0])\n",
    "    temp_df1A['ClusterID'] = pd.Series(temp_list2, index=temp_df1A.index)\n",
    "    temp_df1A = temp_df1A[['PEPTIDE', 'CLUSTER', 'ClusterID', 'INTENSITY_1', 'INTENSITY_2', 'INTENSITY_3', 'INTENSITY_4', 'INTENSITY_5', 'INTENSITY_6', 'INTENSITY_7', 'INTENSITY_8', 'INTENSITY_9', 'INTENSITY_10', 'INTENSITY_11', 'INTENSITY_12', 'INTENSITY_13', 'INTENSITY_14', 'INTENSITY_15', 'INTENSITY_16', 'INTENSITY_17']]\n",
    "    cluster_df1 = temp_df1A.groupby(['ClusterID']).sum().copy()\n",
    "    #Add 1 to each value to ensure no 0 values (necessary for Log transform and subsequent hypothesis testing)\n",
    "    cluster_df1[['INTENSITY_1', 'INTENSITY_2', 'INTENSITY_3', 'INTENSITY_4', 'INTENSITY_5', 'INTENSITY_6', 'INTENSITY_7', 'INTENSITY_8', 'INTENSITY_9', 'INTENSITY_10', 'INTENSITY_11', 'INTENSITY_12', 'INTENSITY_13', 'INTENSITY_14', 'INTENSITY_15', 'INTENSITY_16', 'INTENSITY_17']] += 0\n",
    "    return cluster_df1\n",
    "\n",
    "def normalize_Cluster_Intensity_Table(complete_dataframe_2):\n",
    "    \"\"\"\n",
    "        Input: Cluster-Intensity dataframe\n",
    "        Output: New Cluster-Intensity dataframe with each entry normalized by dividing by respective column sum (note that intensities from peptides mapping to multiple clusters tossed)\n",
    "    \"\"\"\n",
    "    temp_allsums1 = complete_dataframe_2.sum(axis=0, skipna = True)\n",
    "    complete_dataframe_2['INTENSITY_1'] /= temp_allsums1['INTENSITY_1']\n",
    "    complete_dataframe_2['INTENSITY_2'] /= temp_allsums1['INTENSITY_2']\n",
    "    complete_dataframe_2['INTENSITY_3'] /= temp_allsums1['INTENSITY_3']\n",
    "    complete_dataframe_2['INTENSITY_4'] /= temp_allsums1['INTENSITY_4']\n",
    "    complete_dataframe_2['INTENSITY_5'] /= temp_allsums1['INTENSITY_5']\n",
    "    complete_dataframe_2['INTENSITY_6'] /= temp_allsums1['INTENSITY_6']\n",
    "    complete_dataframe_2['INTENSITY_7'] /= temp_allsums1['INTENSITY_7']\n",
    "    complete_dataframe_2['INTENSITY_8'] /= temp_allsums1['INTENSITY_8']\n",
    "    complete_dataframe_2['INTENSITY_9'] /= temp_allsums1['INTENSITY_9']\n",
    "    complete_dataframe_2['INTENSITY_10'] /= temp_allsums1['INTENSITY_10']\n",
    "    complete_dataframe_2['INTENSITY_11'] /= temp_allsums1['INTENSITY_11']\n",
    "    complete_dataframe_2['INTENSITY_12'] /= temp_allsums1['INTENSITY_12']\n",
    "    complete_dataframe_2['INTENSITY_13'] /= temp_allsums1['INTENSITY_13']\n",
    "    complete_dataframe_2['INTENSITY_14'] /= temp_allsums1['INTENSITY_14']\n",
    "    complete_dataframe_2['INTENSITY_15'] /= temp_allsums1['INTENSITY_15']\n",
    "    complete_dataframe_2['INTENSITY_16'] /= temp_allsums1['INTENSITY_16']\n",
    "    complete_dataframe_2['INTENSITY_17'] /= temp_allsums1['INTENSITY_17']\n",
    "    return complete_dataframe_2\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "#----------------------------Formatting and Annotating R-output-----------------------------\n",
    "\n",
    "def annotate_R_abridged(cdhit_file, abridged_R_file):\n",
    "    \"\"\"\n",
    "        Input: CDHIT cluster file and abridged R outputfile containing p-adj values\n",
    "        Output: newly annotated dataframe\n",
    "    \"\"\"\n",
    "    with open(cdhit_file, 'r') as f:\n",
    "        file1 = f.readlines()\n",
    "    cluster_representative_dict1 = {}\n",
    "    for line1 in file1:\n",
    "        line2 = line1.split('\\t')\n",
    "        if line1[0] == '>':\n",
    "            temp_clusternum = line2[0].replace('>Cluster ', '').replace('\\n', '')\n",
    "        elif '... *' in line2[1]:\n",
    "            line3 = line2[1].split(' ')\n",
    "            line4 = line3[1].split('|')\n",
    "            line5 = line4[1]\n",
    "            cluster_representative_dict1[temp_clusternum] = line5\n",
    "            temp_clusternum = \"\"\n",
    "    with open(abridged_R_file, 'r') as g:\n",
    "        file2 = g.readlines()\n",
    "    cluster_rep_list = []\n",
    "    for line1 in file2:\n",
    "        line2 = line1.split(',')\n",
    "        if line2[1] in cluster_representative_dict1.keys():\n",
    "            cluster_rep_list.append(cluster_representative_dict1[line2[1]])\n",
    "    temp_dfC1 = pd.read_csv(abridged_R_file) \n",
    "    temp_dfC1['cluster_representative'] = pd.Series(cluster_rep_list, index=temp_dfC1.index)\n",
    "    return temp_dfC1\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.121624231338501\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "#---------------Prepare Tables for R-analysis of Census PLine Data-------------------\n",
    "\n",
    "#convert census_filled into file with only PLines\n",
    "censusP_df1 = extract_PLines('Census/census-chat-mouse-20318_filled_modded.txt')\n",
    "\n",
    "#extract specific columns from converted census file\n",
    "Norm_PLine_df1 = extract_Norm_Raw_PLine_Intensities(censusP_df1)\n",
    "Non_Norm_PLine_df1 = extract_Raw_PLine_Intensities(censusP_df1)\n",
    "\n",
    "#normalize columns in Non_Norm extracted file\n",
    "Non_Norm_PLine_df1 = normalize_Raw_PLine_Intensities(Non_Norm_PLine_df1)\n",
    "\n",
    "#output files to csv ready for R-analysis\n",
    "Norm_PLine_df1.to_csv('PLine-ChatMouse-NormIntensityTable1.txt', index=False)\n",
    "Non_Norm_PLine_df1.to_csv('PLine-ChatMouse-NonNormIntensityTable1.txt', index=False)\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PTB/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3319: DtypeWarning: Columns (276) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/PTB/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:240: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738.151624917984\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "#--------Prepare Tables for R-analysis of Census SLine Data (Clustering)-------------\n",
    "\n",
    "temp_chatmouse_65 = extract_Intensity_Master('Census/census-chat-mouse-20318_filled_modded.txt', 'CDHIT/cdhitout-mouse-65.clstr')\n",
    "chatmouse_65 = create_Cluster_Intensity_Table(temp_chatmouse_65)\n",
    "#chatmouse_65 = normalize_Cluster_Intensity_Table(chatmouse_65)\n",
    "\n",
    "temp_chatmouse_75 = extract_Intensity_Master('Census/census-chat-mouse-20318_filled_modded.txt', 'CDHIT/cdhitout-mouse-75.clstr')\n",
    "chatmouse_75 = create_Cluster_Intensity_Table(temp_chatmouse_75)\n",
    "#chatmouse_75 = normalize_Cluster_Intensity_Table(chatmouse_75)\n",
    "\n",
    "temp_chatmouse_85 = extract_Intensity_Master('Census/census-chat-mouse-20318_filled_modded.txt', 'CDHIT/cdhitout-mouse-85.clstr')\n",
    "chatmouse_85 = create_Cluster_Intensity_Table(temp_chatmouse_85)\n",
    "#chatmouse_85 = normalize_Cluster_Intensity_Table(chatmouse_85)\n",
    "\n",
    "temp_chatmouse_95 = extract_Intensity_Master('Census/census-chat-mouse-20318_filled_modded.txt', 'CDHIT/cdhitout-mouse-95.clstr')\n",
    "chatmouse_95 = create_Cluster_Intensity_Table(temp_chatmouse_95)\n",
    "#chatmouse_95 = normalize_Cluster_Intensity_Table(chatmouse_95)\n",
    "\n",
    "#Output to txt/csv file\n",
    "chatmouse_65.to_csv('SLine-ChatMouse-NormIntensityTable-65.txt')\n",
    "chatmouse_75.to_csv('SLine-ChatMouse-NormIntensityTable-75.txt')\n",
    "chatmouse_85.to_csv('SLine-ChatMouse-NormIntensityTable-85.txt')\n",
    "chatmouse_95.to_csv('SLine-ChatMouse-NormIntensityTable-95.txt')\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INTENSITY_1</th>\n",
       "      <th>INTENSITY_2</th>\n",
       "      <th>INTENSITY_3</th>\n",
       "      <th>INTENSITY_4</th>\n",
       "      <th>INTENSITY_5</th>\n",
       "      <th>INTENSITY_6</th>\n",
       "      <th>INTENSITY_7</th>\n",
       "      <th>INTENSITY_8</th>\n",
       "      <th>INTENSITY_9</th>\n",
       "      <th>INTENSITY_10</th>\n",
       "      <th>INTENSITY_11</th>\n",
       "      <th>INTENSITY_12</th>\n",
       "      <th>INTENSITY_13</th>\n",
       "      <th>INTENSITY_14</th>\n",
       "      <th>INTENSITY_15</th>\n",
       "      <th>INTENSITY_16</th>\n",
       "      <th>INTENSITY_17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClusterID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [INTENSITY_1, INTENSITY_2, INTENSITY_3, INTENSITY_4, INTENSITY_5, INTENSITY_6, INTENSITY_7, INTENSITY_8, INTENSITY_9, INTENSITY_10, INTENSITY_11, INTENSITY_12, INTENSITY_13, INTENSITY_14, INTENSITY_15, INTENSITY_16, INTENSITY_17]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatmouse_95[chatmouse_95.eq(0).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1139299869537354\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "#---------------Add Protein Labels to R-analysis of Census SLine Data----------------\n",
    "\n",
    "chatmouse_65_log_R1 = annotate_R_abridged('CDHIT/cdhitout-mouse-65.clstr', 'Census_analysis/SLine-ChatMouse-Census-Log2Transform-65.csv')\n",
    "chatmouse_65_log_R1.drop(columns='Unnamed: 0', inplace=True)\n",
    "chatmouse_65_log_R1.to_csv('SLine-ChatMouse-Census-Log2Transform-65-annotated.txt', index=False)\n",
    "\n",
    "chatmouse_75_log_R1 = annotate_R_abridged('CDHIT/cdhitout-mouse-75.clstr', 'Census_analysis/SLine-ChatMouse-Census-Log2Transform-75.csv')\n",
    "chatmouse_75_log_R1.drop(columns='Unnamed: 0', inplace=True)\n",
    "chatmouse_75_log_R1.to_csv('SLine-ChatMouse-Census-Log2Transform-75-annotated.txt', index=False)\n",
    "\n",
    "chatmouse_85_log_R1 = annotate_R_abridged('CDHIT/cdhitout-mouse-85.clstr', 'Census_analysis/SLine-ChatMouse-Census-Log2Transform-85.csv')\n",
    "chatmouse_85_log_R1.drop(columns='Unnamed: 0', inplace=True)\n",
    "chatmouse_85_log_R1.to_csv('SLine-ChatMouse-Census-Log2Transform-85-annotated.txt', index=False)\n",
    "\n",
    "chatmouse_95_log_R1 = annotate_R_abridged('CDHIT/cdhitout-mouse-95.clstr', 'Census_analysis/SLine-ChatMouse-Census-Log2Transform-95.csv')\n",
    "chatmouse_95_log_R1.drop(columns='Unnamed: 0', inplace=True)\n",
    "chatmouse_95_log_R1.to_csv('SLine-ChatMouse-Census-Log2Transform-95-annotated.txt', index=False)\n",
    "\n",
    "\n",
    "#----------\n",
    "\n",
    "chatmouse_65_3r_R1 = annotate_R_abridged('CDHIT/cdhitout-mouse-65.clstr', 'Census_analysis/SLine-ChatMouse-Census-cuberootTransform-65.csv')\n",
    "chatmouse_65_3r_R1.drop(columns='Unnamed: 0', inplace=True)\n",
    "chatmouse_65_3r_R1.to_csv('SLine-ChatMouse-Census-cuberootTransform-65-annotated.txt', index=False)\n",
    "\n",
    "chatmouse_75_3r_R1 = annotate_R_abridged('CDHIT/cdhitout-mouse-75.clstr', 'Census_analysis/SLine-ChatMouse-Census-cuberootTransform-75.csv')\n",
    "chatmouse_75_3r_R1.drop(columns='Unnamed: 0', inplace=True)\n",
    "chatmouse_75_3r_R1.to_csv('SLine-ChatMouse-Census-cuberootTransform-75-annotated.txt', index=False)\n",
    "\n",
    "chatmouse_85_3r_R1 = annotate_R_abridged('CDHIT/cdhitout-mouse-85.clstr', 'Census_analysis/SLine-ChatMouse-Census-cuberootTransform-85.csv')\n",
    "chatmouse_85_3r_R1.drop(columns='Unnamed: 0', inplace=True)\n",
    "chatmouse_85_3r_R1.to_csv('SLine-ChatMouse-Census-cuberootTransform-85-annotated.txt', index=False)\n",
    "\n",
    "chatmouse_95_3r_R1 = annotate_R_abridged('CDHIT/cdhitout-mouse-95.clstr', 'Census_analysis/SLine-ChatMouse-Census-cuberootTransform-95.csv')\n",
    "chatmouse_95_3r_R1.drop(columns='Unnamed: 0', inplace=True)\n",
    "chatmouse_95_3r_R1.to_csv('SLine-ChatMouse-Census-cuberootTransform-95-annotated.txt', index=False)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClusterID</th>\n",
       "      <th>INTENSITY_1</th>\n",
       "      <th>INTENSITY_2</th>\n",
       "      <th>INTENSITY_3</th>\n",
       "      <th>INTENSITY_4</th>\n",
       "      <th>INTENSITY_5</th>\n",
       "      <th>INTENSITY_6</th>\n",
       "      <th>INTENSITY_7</th>\n",
       "      <th>INTENSITY_8</th>\n",
       "      <th>INTENSITY_9</th>\n",
       "      <th>...</th>\n",
       "      <th>INTENSITY_14</th>\n",
       "      <th>INTENSITY_15</th>\n",
       "      <th>INTENSITY_16</th>\n",
       "      <th>INTENSITY_17</th>\n",
       "      <th>p_value</th>\n",
       "      <th>control_mean</th>\n",
       "      <th>treatment_mean</th>\n",
       "      <th>foldchange</th>\n",
       "      <th>padj</th>\n",
       "      <th>cluster_representative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>-15.684713</td>\n",
       "      <td>-14.462591</td>\n",
       "      <td>-14.551343</td>\n",
       "      <td>-14.294296</td>\n",
       "      <td>-12.775558</td>\n",
       "      <td>-14.155657</td>\n",
       "      <td>-14.021253</td>\n",
       "      <td>-13.992334</td>\n",
       "      <td>-13.423281</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.551288</td>\n",
       "      <td>-16.745220</td>\n",
       "      <td>-18.531755</td>\n",
       "      <td>-15.236075</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-14.151225</td>\n",
       "      <td>-16.913045</td>\n",
       "      <td>1.195165</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>E9Q2E4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14147</td>\n",
       "      <td>-9.629501</td>\n",
       "      <td>-8.860266</td>\n",
       "      <td>-9.234132</td>\n",
       "      <td>-8.795709</td>\n",
       "      <td>-10.685092</td>\n",
       "      <td>-8.987012</td>\n",
       "      <td>-9.585652</td>\n",
       "      <td>-8.350959</td>\n",
       "      <td>-9.401814</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.104943</td>\n",
       "      <td>-10.942521</td>\n",
       "      <td>-10.898712</td>\n",
       "      <td>-10.325736</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>-9.281126</td>\n",
       "      <td>-10.681887</td>\n",
       "      <td>1.150926</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>O08807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14346</td>\n",
       "      <td>-10.258886</td>\n",
       "      <td>-10.580672</td>\n",
       "      <td>-10.171253</td>\n",
       "      <td>-10.064396</td>\n",
       "      <td>-11.048504</td>\n",
       "      <td>-10.340718</td>\n",
       "      <td>-10.512314</td>\n",
       "      <td>-10.276662</td>\n",
       "      <td>-10.811294</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.833867</td>\n",
       "      <td>-8.945664</td>\n",
       "      <td>-9.264812</td>\n",
       "      <td>-8.508317</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>-10.451633</td>\n",
       "      <td>-9.291170</td>\n",
       "      <td>0.888968</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>E9PZF0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>-14.439948</td>\n",
       "      <td>-12.792543</td>\n",
       "      <td>-11.844518</td>\n",
       "      <td>-12.065448</td>\n",
       "      <td>-11.557351</td>\n",
       "      <td>-12.447301</td>\n",
       "      <td>-11.718392</td>\n",
       "      <td>-13.183770</td>\n",
       "      <td>-11.844561</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.324057</td>\n",
       "      <td>-14.217472</td>\n",
       "      <td>-15.093547</td>\n",
       "      <td>-14.840587</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-12.432648</td>\n",
       "      <td>-14.532275</td>\n",
       "      <td>1.168880</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>Q8CHI8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6533</td>\n",
       "      <td>-13.363339</td>\n",
       "      <td>-13.945403</td>\n",
       "      <td>-13.468996</td>\n",
       "      <td>-13.763317</td>\n",
       "      <td>-13.950951</td>\n",
       "      <td>-13.287516</td>\n",
       "      <td>-12.278385</td>\n",
       "      <td>-12.552375</td>\n",
       "      <td>-14.337052</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.672006</td>\n",
       "      <td>-10.872345</td>\n",
       "      <td>-10.271885</td>\n",
       "      <td>-12.453936</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>-13.438593</td>\n",
       "      <td>-10.913286</td>\n",
       "      <td>0.812085</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>P63038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>7102</td>\n",
       "      <td>-14.707948</td>\n",
       "      <td>-15.411485</td>\n",
       "      <td>-15.576592</td>\n",
       "      <td>-14.262365</td>\n",
       "      <td>-16.727032</td>\n",
       "      <td>-15.974162</td>\n",
       "      <td>-15.526899</td>\n",
       "      <td>-15.510765</td>\n",
       "      <td>-16.724519</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.592431</td>\n",
       "      <td>-16.149231</td>\n",
       "      <td>-14.750926</td>\n",
       "      <td>-14.932707</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>-15.602419</td>\n",
       "      <td>-15.709525</td>\n",
       "      <td>1.006865</td>\n",
       "      <td>0.995041</td>\n",
       "      <td>Q6NXH9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>14915</td>\n",
       "      <td>-14.058981</td>\n",
       "      <td>-13.735708</td>\n",
       "      <td>-14.401319</td>\n",
       "      <td>-14.697381</td>\n",
       "      <td>-14.580487</td>\n",
       "      <td>-14.617650</td>\n",
       "      <td>-14.350400</td>\n",
       "      <td>-13.592329</td>\n",
       "      <td>-14.233686</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.352471</td>\n",
       "      <td>-12.897237</td>\n",
       "      <td>-12.813253</td>\n",
       "      <td>-14.636399</td>\n",
       "      <td>0.993152</td>\n",
       "      <td>-14.251994</td>\n",
       "      <td>-14.586703</td>\n",
       "      <td>1.023485</td>\n",
       "      <td>0.995515</td>\n",
       "      <td>Q9CRD0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>15652</td>\n",
       "      <td>-16.287852</td>\n",
       "      <td>-16.618478</td>\n",
       "      <td>-17.152414</td>\n",
       "      <td>-17.925100</td>\n",
       "      <td>-16.822791</td>\n",
       "      <td>-16.483510</td>\n",
       "      <td>-17.782845</td>\n",
       "      <td>-18.315386</td>\n",
       "      <td>-16.786650</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.210977</td>\n",
       "      <td>-16.978411</td>\n",
       "      <td>-14.687111</td>\n",
       "      <td>-17.306739</td>\n",
       "      <td>0.995969</td>\n",
       "      <td>-17.130558</td>\n",
       "      <td>-17.191615</td>\n",
       "      <td>1.003564</td>\n",
       "      <td>0.996336</td>\n",
       "      <td>Q9D142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>17573</td>\n",
       "      <td>-8.385133</td>\n",
       "      <td>-7.537781</td>\n",
       "      <td>-8.236383</td>\n",
       "      <td>-8.240587</td>\n",
       "      <td>-8.975537</td>\n",
       "      <td>-8.471668</td>\n",
       "      <td>-7.799192</td>\n",
       "      <td>-8.447231</td>\n",
       "      <td>-7.292174</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.156601</td>\n",
       "      <td>-7.807598</td>\n",
       "      <td>-7.935925</td>\n",
       "      <td>-8.666720</td>\n",
       "      <td>0.996336</td>\n",
       "      <td>-8.153965</td>\n",
       "      <td>-8.144178</td>\n",
       "      <td>0.998800</td>\n",
       "      <td>0.996336</td>\n",
       "      <td>P01592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>8942</td>\n",
       "      <td>-9.007709</td>\n",
       "      <td>-9.434019</td>\n",
       "      <td>-8.637001</td>\n",
       "      <td>-9.240611</td>\n",
       "      <td>-9.120928</td>\n",
       "      <td>-9.048440</td>\n",
       "      <td>-9.410449</td>\n",
       "      <td>-8.625295</td>\n",
       "      <td>-9.323972</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.031392</td>\n",
       "      <td>-8.381520</td>\n",
       "      <td>-8.871346</td>\n",
       "      <td>-8.793797</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>-9.094269</td>\n",
       "      <td>-9.129877</td>\n",
       "      <td>1.003915</td>\n",
       "      <td>0.996336</td>\n",
       "      <td>B1AQ77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1263 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ClusterID  INTENSITY_1  INTENSITY_2  INTENSITY_3  INTENSITY_4  \\\n",
       "1            64   -15.684713   -14.462591   -14.551343   -14.294296   \n",
       "2         14147    -9.629501    -8.860266    -9.234132    -8.795709   \n",
       "3         14346   -10.258886   -10.580672   -10.171253   -10.064396   \n",
       "4           149   -14.439948   -12.792543   -11.844518   -12.065448   \n",
       "5          6533   -13.363339   -13.945403   -13.468996   -13.763317   \n",
       "...         ...          ...          ...          ...          ...   \n",
       "1259       7102   -14.707948   -15.411485   -15.576592   -14.262365   \n",
       "1260      14915   -14.058981   -13.735708   -14.401319   -14.697381   \n",
       "1261      15652   -16.287852   -16.618478   -17.152414   -17.925100   \n",
       "1262      17573    -8.385133    -7.537781    -8.236383    -8.240587   \n",
       "1263       8942    -9.007709    -9.434019    -8.637001    -9.240611   \n",
       "\n",
       "      INTENSITY_5  INTENSITY_6  INTENSITY_7  INTENSITY_8  INTENSITY_9  ...  \\\n",
       "1      -12.775558   -14.155657   -14.021253   -13.992334   -13.423281  ...   \n",
       "2      -10.685092    -8.987012    -9.585652    -8.350959    -9.401814  ...   \n",
       "3      -11.048504   -10.340718   -10.512314   -10.276662   -10.811294  ...   \n",
       "4      -11.557351   -12.447301   -11.718392   -13.183770   -11.844561  ...   \n",
       "5      -13.950951   -13.287516   -12.278385   -12.552375   -14.337052  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "1259   -16.727032   -15.974162   -15.526899   -15.510765   -16.724519  ...   \n",
       "1260   -14.580487   -14.617650   -14.350400   -13.592329   -14.233686  ...   \n",
       "1261   -16.822791   -16.483510   -17.782845   -18.315386   -16.786650  ...   \n",
       "1262    -8.975537    -8.471668    -7.799192    -8.447231    -7.292174  ...   \n",
       "1263    -9.120928    -9.048440    -9.410449    -8.625295    -9.323972  ...   \n",
       "\n",
       "      INTENSITY_14  INTENSITY_15  INTENSITY_16  INTENSITY_17   p_value  \\\n",
       "1       -17.551288    -16.745220    -18.531755    -15.236075  0.000016   \n",
       "2       -11.104943    -10.942521    -10.898712    -10.325736  0.000078   \n",
       "3        -8.833867     -8.945664     -9.264812     -8.508317  0.000077   \n",
       "4       -15.324057    -14.217472    -15.093547    -14.840587  0.000056   \n",
       "5        -9.672006    -10.872345    -10.271885    -12.453936  0.000080   \n",
       "...            ...           ...           ...           ...       ...   \n",
       "1259    -15.592431    -16.149231    -14.750926    -14.932707  0.991892   \n",
       "1260    -12.352471    -12.897237    -12.813253    -14.636399  0.993152   \n",
       "1261    -17.210977    -16.978411    -14.687111    -17.306739  0.995969   \n",
       "1262     -8.156601     -7.807598     -7.935925     -8.666720  0.996336   \n",
       "1263     -9.031392     -8.381520     -8.871346     -8.793797  0.995951   \n",
       "\n",
       "      control_mean  treatment_mean  foldchange      padj  \\\n",
       "1       -14.151225      -16.913045    1.195165  0.010084   \n",
       "2        -9.281126      -10.681887    1.150926  0.016900   \n",
       "3       -10.451633       -9.291170    0.888968  0.016900   \n",
       "4       -12.432648      -14.532275    1.168880  0.016900   \n",
       "5       -13.438593      -10.913286    0.812085  0.016900   \n",
       "...            ...             ...         ...       ...   \n",
       "1259    -15.602419      -15.709525    1.006865  0.995041   \n",
       "1260    -14.251994      -14.586703    1.023485  0.995515   \n",
       "1261    -17.130558      -17.191615    1.003564  0.996336   \n",
       "1262     -8.153965       -8.144178    0.998800  0.996336   \n",
       "1263     -9.094269       -9.129877    1.003915  0.996336   \n",
       "\n",
       "      cluster_representative  \n",
       "1                     E9Q2E4  \n",
       "2                     O08807  \n",
       "3                     E9PZF0  \n",
       "4                     Q8CHI8  \n",
       "5                     P63038  \n",
       "...                      ...  \n",
       "1259                  Q6NXH9  \n",
       "1260                  Q9CRD0  \n",
       "1261                  Q9D142  \n",
       "1262                  P01592  \n",
       "1263                  B1AQ77  \n",
       "\n",
       "[1263 rows x 24 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatmouse_65_t_R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
